<!doctype html>
  <!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
  <!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
  <!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
  <!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title></title>
    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Place favicon.ico and apple-touch-icon.png in the root directory -->

    <!-- Bootstrap Core CSS -->
    <link href="/css/bootstrap.min.css" rel="stylesheet">

    <!-- MetisMenu CSS -->
    <link href="/css/plugins/metisMenu/metisMenu.min.css" rel="stylesheet">

    <!-- Timeline CSS -->
    <link href="/css/plugins/timeline.css" rel="stylesheet">
    
    <!-- Custom CSS -->
    <link href="/css/sb-admin-2.css" rel="stylesheet">

    <!-- Morris Charts CSS -->
    <!-- link href="/css/plugins/morris.css" rel="stylesheet" -->

    <!-- Custom Fonts -->
    <link href="/font-awesome-4.1.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">

    <!-- Our CSS sheets -->
    <link rel="stylesheet" href="/css/main.css">


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
    
  </head>
  <body>
    <div id="#wrapper">



        <!-- Navigation -->
        <nav class="navbar navbar-default navbar-static-top" role="navigation" style="margin-bottom: 0">
          <!-- div class="navbar-inner" -->
          <!-- div class="container" -->
            <div class="navbar-header">
              <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
              <a class="navbar-brand" href="index.html"><big>PolarSys Maturity Assessment Dashboard &mdash; Metrics</big></a>
            </div>
            <!-- /div -->
            <!-- /div -->
            <!-- /.navbar-header -->
              <div class="navbar-default sidebar" role="navigation">
                <div class="sidebar-nav navbar-collapse">
                  <ul class="nav" id="side-menu">
                    <li class="active"><a href="/index.html">Home</a></li>
                    <li class="active"><a href="/about.html">About</a></li>
                    <li class="active"><a href="/documentation/">Documentation<span class="fa arrow"></span></a>
                      <ul class="nav nav-second-level active">
                    <li><a href="/documentation/quality_model.html">Quality Model</a></li>
                    <li><a href="/documentation/attributes.html">Attributes</a></li>
                    <li><a href="/documentation/questions.html">Questions</a></li>
                    <li><a href="/documentation/metrics.html">Metrics</a></li>
                    <li><a href="/documentation/rules.html">Practices</a></li>
                    <li><a href="/">Actions</a></li>
                    <li><a href="/documentation/references.html">References</a></li>
                  </ul></li>
                    <li class="active"><a href="/projects/">Projects<span class="fa arrow"></span></a>
                      <ul class="nav nav-second-level active">
                    <li><a href="/projects/cdt.html">CDT</a></li>
                    <li><a href="/projects/ease.html">EASE</a></li>
                    <li><a href="/projects/example.html">Example</a></li>
                    <li><a href="/projects/gendoc.html">Gendoc</a></li>
                    <li><a href="/projects/kitalpha.html">Kitalpha</a></li>
                    <li><a href="/projects/papyrus.html">Papyrus</a></li>
                    <li><a href="/projects/sirius.html">Sirius</a></li>
                  </ul></li>
                    <li class="active"><a href="/contact.html">Contact</a></li></ul>
          </div></div>
        </nav>


        <div id="page-wrapper">
          <div class="row">
            <div class="col-lg-12">
              <h2>Definition of metrics</h2>
              <p>All metrics used in the maturity assessment process are described thereafter, with useful information and references.</p><br />
        
 
              <div class="tabbable">
                <ul class="nav nav-tabs" role="tablist">
                  <li role="presentation" class="active"><a href="#repo_all" role="tab" data-toggle="tab">All&nbsp;<span class="badge">78</span></a></li>
                  <li role="presentation">
                    <a href="#repo_Grimoire" role="tab" data-toggle="tab">Grimoire&nbsp;<span class="badge">21</span></a></li>
                  <li role="presentation">
                    <a href="#repo_Manual" role="tab" data-toggle="tab">Manual&nbsp;<span class="badge">2</span></a></li>
                  <li role="presentation">
                    <a href="#repo_MarketplaceScript" role="tab" data-toggle="tab">MarketplaceScript&nbsp;<span class="badge">3</span></a></li>
                  <li role="presentation">
                    <a href="#repo_PMI" role="tab" data-toggle="tab">PMI&nbsp;<span class="badge">5</span></a></li>
                  <li role="presentation">
                    <a href="#repo_RuleCheckingScript" role="tab" data-toggle="tab">RuleCheckingScript&nbsp;<span class="badge">20</span></a></li>
                  <li role="presentation">
                    <a href="#repo_SonarQube" role="tab" data-toggle="tab">SonarQube&nbsp;<span class="badge">23</span></a></li>
                  <li role="presentation">
                    <a href="#repo_Unknown" role="tab" data-toggle="tab">Unknown&nbsp;<span class="badge">4</span></a></li>
                </ul>
                <div class="tab-content">
                <div role="tabpanel" class="tab-pane fade in active" id="repo_all"><br />
                  <ul class="list-group">
                <li class="list-group-item"><p id="ATTRS"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Average number of attributes</strong> ( ATTRS )</p>
<p class="desc">Average number of attributes defined in a class. This can be compared to the <a href="/documentation/metrics.html#TOPD">total number of operands</a> (TOPD) considered at the class level, and is representative of the data complexity of the class (not including the complexity of methods).</p>
</li>
                <li class="list-group-item"><p id="ATTRS_PUBLIC"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Average number of public attributes</strong> ( ATTRS_PUBLIC )</p>
<p class="desc">Average number of attributes defined in classes with a <code>public</code> modifier.</p>
<p class="desc">Publicness of attributes is meaningful for reusability: if there are a lot of public attributes available, it may be more time-consuming to find the right one. Also, good practices for object-oriented programming recommend to use getters and setters in most cases.</p>
</li>
                <li class="list-group-item"><p id="CLASSES"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of classes</strong> ( CLASSES )</p>
<p class="desc">The number of Java classes, including nested classes, interfaces, enums and annotations.</p>
<p class="desc">The SonarQube measure used for this purpose is <mark>classes</mark>. This metric is often used as rule-of-thumb indicator for the size of software, and to make other measures relatives.</p>
<p class="desc">See also SonarQube's definitions for size metrics: <a href="http://docs.codehaus.org/display/SONAR/Metric+definitions#Metricdefinitions-Size">http://docs.codehaus.org/display/SONAR/Metric+definitions#Metricdefinitions-Size</a>.</p>
</li>
                <li class="list-group-item"><p id="CLONE_IDX"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Cloning density</strong> ( CLONE_IDX )</p>
<p class="desc">The amount of duplicated lines in the code, divided by the number of lines. The SonarQube metric used for this purpose is <mark>duplicated_lines_density</mark>.</p>
<p class="desc">See also SonarQube's definition for duplications: <a href="http://docs.codehaus.org/display/SONAR/Metric+definitions#Metricdefinitions-Duplications">http://docs.codehaus.org/display/SONAR/Metric+definitions#Metricdefinitions-Duplications</a>. There is a longer description of the code cloning algorithm here: <a href="http://docs.codehaus.org/display/SONAR/Duplications">http://docs.codehaus.org/display/SONAR/Duplications</a>.</p>
</li>
                <li class="list-group-item"><p id="COMR"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Comment rate</strong> ( COMR )</p>
<p class="desc">The ratio of source lines of code on the number of comment lines of code.</p>
<p class="desc">Density of comment lines = Comment lines / (Lines of code + Comment lines) * 100. With such a formula, <var>50%</var> means that the number of lines of code equals the number of comment lines and <var>100%</var> means that the file only contains comment lines. The SonarQube measure used for this purpose is <mark>comment_lines_density</mark>. </p>
<p class="desc">See also SonarQube's page on comment lines metrics: <a href="http://docs.codehaus.org/display/SONAR/Metrics+-+Comment+lines">http://docs.codehaus.org/display/SONAR/Metrics+-+Comment+lines</a>.</p>
</li>
                <li class="list-group-item"><p id="DL_REPO_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of downloads on the web site</strong> ( DL_REPO_1M )</p>
<p class="desc">The number of downloads on the web site of the project (download page) during last month. Example of download page (for CDT) : http://www.eclipse.org/downloads/ .</p>
</li>
                <li class="list-group-item"><p id="DL_UPDATE_SITE_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of downloads on update site</strong> ( DL_UPDATE_SITE_1M )</p>
<p class="desc">The number of downloads on the update site of the project during last month. Is computed using successful and failed installs from marketplace.</p>
</li>
                <li class="list-group-item"><p id="DOPD"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of distinct operands</strong> ( DOPD )</p>
<p class="desc">The number of distinct operands found in the function. The measure was first introduced by Halstead in his <i>Elements of Software Sience</i> [<a href="Halstead1977">Halstead</a>]. An operand is an entity on which an operation is performed: e.g. a variable, constant, number. An operator is a construct that performs an operation: e.g. a function, concatenation, addition.</p>
<p class="desc">Useful measures derived from the set of Halstead operators include program vocabulary (<var>n</var>), program length (<var>N</var>), program volume (<var>V</var>) or estimated effort needed for program comprehension (<var>E</var>).</p>
<p class="desc">See also the Maisqual wiki: <a href="http://maisqual.squoring.com/wiki/index.php/Category:Halstead_Metrics">http://maisqual.squoring.com/wiki/index.php/Category:Halstead_Metrics</a>.</p>
</li>
                <li class="list-group-item"><p id="DOPT"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of distinct operators</strong> ( DOPT )</p>
<p class="desc">The number of distinct operators found in the function. The measure was first introduced by Halstead in his <i>Elements of Software Sience</i> [<a href="Halstead1977">Halstead</a>]. An operand is an entity on which an operation is performed: e.g. a variable, constant, number. An operator is a construct that performs an operation: e.g. a function, concatenation, addition.</p>
<p class="desc">Useful measures derived from the set of Halstead operators include program vocabulary (<var>n</var>), program length (<var>N</var>), program volume (<var>V</var>) or estimated effort needed for program comprehension (<var>E</var>).</p>
<p class="desc">See also the Maisqual wiki: <a href="http://maisqual.squoring.com/wiki/index.php/Category:Halstead_Metrics">http://maisqual.squoring.com/wiki/index.php/Category:Halstead_Metrics</a>.</p>
</li>
                <li class="list-group-item"><p id="FILES"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of files</strong> ( FILES )</p>
<p class="desc">The number of code files (e.g. with a <code>.java</code> for the Java language) in the source code hierarchy. The SonarQube measure used for this purpose is <mark>files</mark>. This metric is often used as rule-of-thumb indicator for the size of software, and to make other measures relatives.</p>
</li>
                <li class="list-group-item"><p id="FUNCTIONS"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of functions</strong> ( FUNCTIONS )</p>
<p class="desc">The number of functions defined in the source files.</p>
<p class="desc">The SonarQube measure used for this purpose is <mark>functions</mark>. This metric is often used as rule-of-thumb indicator for the size of software, and to make other measures relatives.</p>
<p class="desc">See also SonarQube's definitions for size metrics: <a href="http://docs.codehaus.org/display/SONAR/Metric+definitions#Metricdefinitions-Size">http://docs.codehaus.org/display/SONAR/Metric+definitions#Metricdefinitions-Size</a>. More details on the metric: <a href="http://docs.codehaus.org/display/SONAR/Metrics+-+Methods">http://docs.codehaus.org/display/SONAR/Metrics+-+Methods</a>.</p>
</li>
                <li class="list-group-item"><p id="IP_LOG_COV"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>IP log code coverage</strong> ( IP_LOG_COV )</p>
<p class="desc">Percentage of contributions covered by an appropriate IP log.</p>
<p class="desc">Eclipse foundation has a very strict <a href="https://www.eclipse.org/org/documents/Eclipse_IP_Policy.pdf">IP policy</a> and this measure should always be 100%.</p>
</li>
                <li class="list-group-item"><p id="ITS_AUTH_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>ITS authors</strong> ( ITS_AUTH_1M )</p>
<p class="desc">Number of distinct identities updating tickets during the last month, in the issue tracking system, divided by the number of thousands of lines of code.</p>
<p class="desc">The subset of tickets considered from the issue tracking system are those specified in the project documentation, for example by specifying a tracker or a project name appearing in ticket data. Update means an operation on a ticket changing its state, or adding information. Opening and closing a ticket are considered as updates. Identities of updaters are the character strings found in the corresponding field in the ticket information. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). Number of lines are those calculated at the end of the period of analysis.</p>
</li>
                <li class="list-group-item"><p id="ITS_BUGS_DENSITY"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Defect density</strong> ( ITS_BUGS_DENSITY )</p>
<p class="desc">Ratio of the total number of tickets in the issue tracking system to the size of the source code in KLOC, at the time of the data retrieval. </p>
<p class="desc">The subset of tickets considered from the issue tracking system are those specified in the project documentation, for example by specifying a tracker or a project name appearing in ticket data. Source code is all source code found in the source code management repository.</p>
</li>
                <li class="list-group-item"><p id="ITS_BUGS_OPEN"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of open bugs</strong> ( ITS_BUGS_OPEN )</p>
<p class="desc">Number of tickets marked as still open at the time of the data retrieval, in the issue tracking system, divided by the number of thousands of lines of code.</p>
<p class="desc">The subset of tickets considered from the issue tracking system are those specified in the project documentation, for example by specifying a tracker or a project name appearing in ticket data. Open means the state in which further actions are usually expected until the ticket is closed. Number of lines are those calculated at the end of the period of analysis.</p>
</li>
                <li class="list-group-item"><p id="ITS_FIX_MED_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Median time to fix bug</strong> ( ITS_FIX_MED_1M )</p>
<p class="desc">Median period from when a ticket is open to when a ticket is closed, for all tickets closed during the last month, in the issue tracking system. </p>
<p class="desc">The subset of tickets considered from the issue tracking system are those specified in the project documentation, for example by specifying a tracker or a project name appearing in ticket data. Closed means the state in which no further action is usually performed in the ticket. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). Unit is days.</p>
</li>
                <li class="list-group-item"><p id="ITS_ISSUES_OPENERS_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of issue openers during last month</strong> ( ITS_ISSUES_OPENERS_1M )</p>
<p class="desc">Number of distinct identities opening tickets during the last month, in the issue tracking system, divided by the number of thousands of lines of code.</p>
<p class="desc">The subset of tickets considered from the issue tracking system are those specified in the project documentation, for example by specifying a tracker or a project name appearing in ticket data. Opened means that the ticket information was submitted to the issue traking system for the first time for that ticket. Identities of openers are the character strings found in the corresponding field in the ticket information. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). Number of lines are those calculated at the end of the period of analysis.</p>
</li>
                <li class="list-group-item"><p id="ITS_ISSUES_OPEN_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of issues opened during last month</strong> ( ITS_ISSUES_OPEN_1M )</p>
<p class="desc">Number of tickets opened (new) during the last month, in the issue tracking system out, divided by the number of thousands of lines of code</p>
<p class="desc">The subset of tickets considered from the issue tracking system are those specified in the project documentation, for example by specifying a tracker or a project name appearing in ticket data. Opened means that the ticket information was submitted to the issue traking system for the first time for that ticket. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). Number of lines are those calculated at the end of the period of analysis.</p>
</li>
                <li class="list-group-item"><p id="ITS_UPDATES_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>ITS updates</strong> ( ITS_UPDATES_1M )</p>
<p class="desc">Number of updates to tickets during the last month, in the issue tracking system, divided by the number of thousands of lines of code.</p>
<p class="desc">The subset of tickets considered from the issue tracking system are those specified in the project documentation, for example by specifying a tracker or a project name appearing in ticket data. Update means an operation on a ticket changing its state, or adding information. Opening and closing a ticket are considered as updates. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). Number of lines are those calculated at the end of the period of analysis.</p>
</li>
                <li class="list-group-item"><p id="LIC_IDENT"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>License identification</strong> ( LIC_IDENT )</p>
<p class="desc">Is there a list of the different licences used in the product?</p>
<p class="desc">This measure may use an external tool like Ninka (<a href="http://ninka.turingmachine.org/">ninka.turingmachine.org</a>) to identify the licence of components used in the project. Another way would be to identify a file named LICENCES in the root folder.</p>
</li>
                <li class="list-group-item"><p id="MDIT"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Depth of Inheritance Tree</strong> ( MDIT )</p>
<p class="desc">The maximum depth of inheritance tree of a class within the inheritance hierarchy is defined as the maximum length from the considered class to the root of the class hierarchy tree and is measured by the number of ancestor classes. In cases involving multiple inheritance, the MDIT is the maximum length from the node to the root of the tree [<a href="/documentation/references.html#Chidamber1994">Chidamber1994</a>].</p>
<p class="desc">A deep inheritance tree makes the understanding of the object-oriented architecture difficult. Well structured OO systems have a forest of classes rather than one large inheritance lattice. The deeper the class is within the hierarchy, the greater the number of methods it is likely to inherit, making it more complex to predict its behavior and, therefore, more fault-prone [<a href="/documentation/references.html#Chidamber1994">Chidamber1994</a>]. However, the deeper a particular tree is in a class, the greater potential reuse of inherited methods [<a href="/documentation/references.html#Chidamber1994">Chidamber1994</a>].</p>
<p class="desc">See also SonarQube's page on the depth in tree: <a href="http://docs.codehaus.org/display/SONAR/Metrics+-+Depth+in+Tree">http://docs.codehaus.org/display/SONAR/Metrics+-+Depth+in+Tree</a></p>
</li>
                <li class="list-group-item"><p id="METHS"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Average number of methods</strong> ( METHS )</p>
<p class="desc">Average number of methods defined in the class. This can be compared to the <a href="/documentation/metrics.html#TOPD">total number of operators</a> (TOPT) considered at the class level.</p>
</li>
                <li class="list-group-item"><p id="METHS_PUBLIC"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Average number of public methods</strong> ( METHS_PUBLIC )</p>
<p class="desc">Average number of methods defined in classes with a <code>public</code> modifier.</p>
<p class="desc">Publicness of methods is meaningful for reusability: if there are a lot of public methods available, it may be more time-consuming to find the right one.</p>
</li>
                <li class="list-group-item"><p id="MKT_FAV"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of favourites on the Marketplace</strong> ( MKT_FAV )</p>
<p class="desc">The number of favourites on the Eclipse Marketplace for the project.</p>
<p class="desc">This measure uses the MarketPlace REST API to retrieve the number of registered users who marked this project as a favourite. If the project is not registered on the Marketplace, the metric should be zero.</p>
</li>
                <li class="list-group-item"><p id="MKT_INSTALL_FAILED_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of failed install on the Marketplace</strong> ( MKT_INSTALL_FAILED_1M )</p>
<p class="desc">The number of failed installs for the project as reported on the Marketplace during the last month.</p>
<p class="desc">THis measure uses the list of failed installs available on the Marketplace for every registered project. Here is <a href="http://marketplace.eclipse.org/unsuccessful/installs/1373403/error_report.csv">an example of log page</a>, errors tab. If the project is not registered on the Marketplace, the metric should be zero.</p>
</li>
                <li class="list-group-item"><p id="MKT_INSTALL_SUCCESS_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of successfull installs on the Marketplace</strong> ( MKT_INSTALL_SUCCESS_1M )</p>
<p class="desc">The number of successful installs for the project as reported on the Marketplace during the last month.</p>
<p class="desc">This measure uses the list of successful installs available on the Marketplace for every registered project. Here is <a href="http://marketplace.eclipse.org/content/eclipse-cdt-cc-development-tooling">an example of log page</a>, metrics tab. If the project is not registered on the Marketplace, the metric should be zero.</p>
</li>
                <li class="list-group-item"><p id="MLS_DEV_AUTH_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Developer ML authors</strong> ( MLS_DEV_AUTH_1M )</p>
<p class="desc">Number of distinct senders for messages dated during the last month, in developer mailing list archives, divided by the number of thousands of lines of code. </p>
<p class="desc">Developer mailing list is the list or lists considered as 'for developers' in the project documentation. The date used is the mailing list server date, as stamped in the message. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). Distinct senders are those with distinct email addresses. Email addresses used are the strings found in 'From:' fields in messages. The number of lines are those calculated at the end of the period of analysis.</p>
</li>
                <li class="list-group-item"><p id="MLS_DEV_RESP_RATIO_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Developer ML response ratio</strong> ( MLS_DEV_RESP_RATIO_1M )</p>
<p class="desc">Average number of messages in thread, minus one, for all threds of messages dated during the last month, in developer mailing list archives. </p>
<p class="desc">Threads are identified using 'In-Reply-To' message headers. Developer mailing list is the list or lists considered as 'for developers' in the project documentation. The date used is the mailing list server date, as stamped in the message. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included).</p>
</li>
                <li class="list-group-item"><p id="MLS_DEV_RESP_TIME_MED_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Developer ML response time</strong> ( MLS_DEV_RESP_TIME_MED_1M )</p>
<p class="desc">Median period from first message in thread to second message in thread, for all threds with at least two messages dated during the last month, in developer mailing list archives. </p>
<p class="desc">Threads are identified using 'In-Reply-To' message headers. Developer mailing list is the list or lists considered as 'for developers' in the project documentation. The date used is the mailing list server date, as stamped in the message. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). Unit is days.</p>
</li>
                <li class="list-group-item"><p id="MLS_DEV_SUBJ_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Developer ML subjects</strong> ( MLS_DEV_SUBJ_1M )</p>
<p class="desc">Number of threds of messages dated during the last month, in developer mailing list archives, divided by the number of thousands of lines of code. </p>
<p class="desc">Threads are identified using 'In-Reply-To' message headers. Developer mailing list is the list or lists considered as 'for developers' in the project documentation. The date used is the mailing list server date, as stamped in the message. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). The number of lines are those calculated at the end of the period of analysis.</p>
</li>
                <li class="list-group-item"><p id="MLS_DEV_VOL_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Developer ML posts</strong> ( MLS_DEV_VOL_1M )</p>
<p class="desc">Number of messages dated during the last month, in developer mailing list archives, divided by the number of thousands of lines of code.</p>
<p class="desc">Developer mailing list is the list or lists considered as 'for developers' in the project documentation. The date used is the mailing list server date, as stamped in the message. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). The number of lines are those calculated at the end of the period of analysis.</p>
</li>
                <li class="list-group-item"><p id="MLS_USR_AUTH_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>User ML authors</strong> ( MLS_USR_AUTH_1M )</p>
<p class="desc">Number of distinct senders for messages dated during the last month, in user mailing list archives, divided by the number of thousands of lines of code.</p>
<p class="desc">User mailing list is the list or lists considered as 'for users' in the project documentation. The date used is the mailing list server date, as stamped in the message. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). Distinct senders are those with distinct email addresses. Email addresses used are the strings found in 'From:' fields in messages. The number of lines are those calculated at the end of the period of analysis.</p>
</li>
                <li class="list-group-item"><p id="MLS_USR_RESP_RATIO_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>User ML response ratio</strong> ( MLS_USR_RESP_RATIO_1M )</p>
<p class="desc">Average number of messages in thread, minus one, for all threds of messages dated during the last month, in user mailing list archives. </p>
<p class="desc">Threads are identified using 'In-Reply-To' message headers. User mailing list is the list or lists considered as 'for users' in the project documentation. The date used is the mailing list server date, as stamped in the message. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included).</p>
</li>
                <li class="list-group-item"><p id="MLS_USR_RESP_TIME_MED_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>User ML response time</strong> ( MLS_USR_RESP_TIME_MED_1M )</p>
<p class="desc">Median period from first message in thread to second message in thread, for all threds with at least two messages dated during the last month, in user mailing list archives. </p>
<p class="desc">Threads are identified using 'In-Reply-To' message headers. User mailing list is the list or lists considered as 'for users' in the project documentation. The date used is the mailing list server date, as stamped in the message. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). Unit is days.</p>
</li>
                <li class="list-group-item"><p id="MLS_USR_SUBJ_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>User ML subjects</strong> ( MLS_USR_SUBJ_1M )</p>
<p class="desc">Number of threds of messages dated during the last month, in user mailing list archives, divided by the number of thousands of lines of code.</p>
<p class="desc">Threads are identified using 'In-Reply-To' message headers. User mailing list is the list or lists considered as 'for users' in the project documentation. The date used is the mailing list server date, as stamped in the message. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). The number of lines are those calculated at the end of the period of analysis.</p>
</li>
                <li class="list-group-item"><p id="MLS_USR_VOL_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>User ML posts</strong> ( MLS_USR_VOL_1M )</p>
<p class="desc">Number of messages dated during the last month, in user mailing list archives, divided by the number of thousands of lines of code. </p>
<p class="desc">User mailing list is the list or lists considered as 'for users' in the project documentation. The date used is the mailing list server date, as stamped in the message. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). The number of lines are those calculated at the end of the period of analysis.</p>
</li>
                <li class="list-group-item"><p id="NCC_ANA"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of non-conformities for analysability</strong> ( NCC_ANA )</p>
<p class="desc">The total number of violations of rules that impact analysability in the source code.</p>
<p class="desc">See also the <a href="/documentation/rules.html">page on practices</a> for a list of checked rules and their associated impact on quality characteristics.</p>
</li>
                <li class="list-group-item"><p id="NCC_ANA_IDX"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Average number of non-conformities for analysability</strong> ( NCC_ANA_IDX )</p>
<p class="desc">The total number of violations of rules that impact analysability in the source code, divided by the number of thousands of lines of code.</p>
<p class="desc">See also the <a href="/documentation/rules.html">page on practices</a> for a list of checked rules and their associated impact on quality characteristics.</p>
</li>
                <li class="list-group-item"><p id="NCC_CHA"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of non-conformities for changeability</strong> ( NCC_CHA )</p>
<p class="desc">The total number of violations of rules that impact changeability in the source code.</p>
<p class="desc">See also the <a href="/documentation/rules.html">page on practices</a> for a list of checked rules and their associated impact on quality characteristics.</p>
</li>
                <li class="list-group-item"><p id="NCC_CHA_IDX"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Average number of non-conformities for changeability</strong> ( NCC_CHA_IDX )</p>
<p class="desc">The total number of violations of rules that impact changeability in the source code, divided by the number of thousands of lines of code.</p>
<p class="desc">See also the <a href="/documentation/rules.html">page on practices</a> for a list of checked rules and their associated impact on quality characteristics.</p>
</li>
                <li class="list-group-item"><p id="NCC_REL"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of non-conformities for reliability</strong> ( NCC_REL )</p>
<p class="desc">The total number of violations of rules that impact reliability in the source code.</p>
<p class="desc">See also the <a href="/documentation/rules.html">page on practices</a> for a list of checked rules and their associated impact on quality characteristics.</p>
</li>
                <li class="list-group-item"><p id="NCC_REL_IDX"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Average number of non-conformities for reliability</strong> ( NCC_REL_IDX )</p>
<p class="desc">The total number of violations of rules that impact reliability in the source code, divided by the number of thousands of lines of code.</p>
<p class="desc">See also the <a href="/documentation/rules.html">page on practices</a> for a list of checked rules and their associated impact on quality characteristics.</p>
</li>
                <li class="list-group-item"><p id="NCC_REU"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of non-conformities for reusability</strong> ( NCC_REU )</p>
<p class="desc">The total number of violations of rules that impact reusability in the source code.</p>
<p class="desc">See also the <a href="/documentation/rules.html">page on practices</a> for a list of checked rules and their associated impact on quality characteristics.</p>
</li>
                <li class="list-group-item"><p id="NCC_REU_IDX"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Average number of non-conformities for reusability</strong> ( NCC_REU_IDX )</p>
<p class="desc">The total number of violations of rules that impact reusability in the source code, divided by the number of thousands of lines of code.</p>
<p class="desc">See also the <a href="/documentation/rules.html">page on practices</a> for a list of checked rules and their associated impact on quality characteristics.</p>
</li>
                <li class="list-group-item"><p id="NEST"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Maximum depth of nesting</strong> ( NEST )</p>
<p class="desc">The maximum depth of nesting counts the highest number of imbricated code (including conditions and loops) in a function. </p>
<p class="desc">Deeper nesting threatens understandability of code and induces more test cases to run the different branches. Practitioners usually consider that a function with three or more nested levels becomes significantly more difficult for the human mind to apprehend how it works.</p>
</li>
                <li class="list-group-item"><p id="PLAN_MILESTONES_VOL_1Y"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of milestones</strong> ( PLAN_MILESTONES_VOL_1Y )</p>
<p class="desc">The number of milestones that occured during the last year.</p>
<p class="desc">Milestones are retrieved from the PMI file and are counted whatever their target release is. Milestones are useful to assess the maturity of the release and improves predictability of the project's output, in terms of quality and time.</p>
</li>
                <li class="list-group-item"><p id="PLAN_NEXT_MILESTONE"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Project is on time for next milestone</strong> ( PLAN_NEXT_MILESTONE )</p>
<p class="desc">Is the project on time for the next milestone?</p>
</li>
                <li class="list-group-item"><p id="PLAN_REVIEWS_SUCCESS_RATE"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Milestone success rate</strong> ( PLAN_REVIEWS_SUCCESS_RATE )</p>
<p class="desc">What is the percentage of successful reviews over the past 5 releases?</p>
<p class="desc">The reviews are retrieved from the project management infrastructure record, and are considered successful if the entry is equal to <mark>success</mark>. If there are less than 5 releases defined, the percentage is computed on these only.</p>
</li>
                <li class="list-group-item"><p id="PUBLIC_API"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Public API</strong> ( PUBLIC_API )</p>
<p class="desc">Number of public Classes + number of public Functions + number of public Properties. The SonarQube measure used for this purpose is <mark>public_api</mark>.</p>
<p class="desc">See also SonarQube's definition for size metrics: <a href="http://docs.codehaus.org/display/SONAR/Metric+definitions#Metricdefinitions-Size">http://docs.codehaus.org/display/SONAR/Metric+definitions#Metricdefinitions-Size</a>. More details can be seen here: <a href="http://docs.codehaus.org/display/SONAR/Metrics+-+Public+API">http://docs.codehaus.org/display/SONAR/Metrics+-+Public+API</a></p>
</li>
                <li class="list-group-item"><p id="PUBLIC_API_DOC"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Public documented API</strong> ( PUBLIC_API_DOC )</p>
<p class="desc">The percentage of documented API accesses. Density of public documented API = (Public API - Public undocumented API) / Public API * 100. The SonarQube measure used for this purpose is <mark>public_documented_api_density</mark>.</p>
<p class="desc">See also SonarQube's definition for size metrics: <a href="http://docs.codehaus.org/display/SONAR/Metric+definitions#Metricdefinitions-Size">http://docs.codehaus.org/display/SONAR/Metric+definitions#Metricdefinitions-Size</a>. </p>
</li>
                <li class="list-group-item"><p id="PUB_CONF_VOL"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of publications</strong> ( PUB_CONF_VOL )</p>
<p class="desc">The number of papers published in conferences, journals, and public web sites.</p>
<p class="desc">This metric is not yet active because its retrieval is being debated.</p>
</li>
                <li class="list-group-item"><p id="PUB_ITS_INFO_PMI"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>ITS information</strong> ( PUB_ITS_INFO_PMI )</p>
<p class="desc">Is the bugzilla info correctly filled in the PMI records?</p>
<p class="desc">The project management infrastructure file holds information about one or more bugzilla instances. This test checks that at least one bugzilla instance is defined, with a product identifier, a create_url to enter a new issue, and a query_url to fetch all the issues for the project.</p>
</li>
                <li class="list-group-item"><p id="PUB_SCM_INFO_PMI"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>SCM information</strong> ( PUB_SCM_INFO_PMI )</p>
<p class="desc">Is the source_repo info correctly filled in the PMI records? </p>
<p class="desc">The project management infrastructure file holds information about one or more source repositories. This test checks that at least one source repository is defined, and accessible.</p>
</li>
                <li class="list-group-item"><p id="RKO_ANA"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of violated rules for analysability</strong> ( RKO_ANA )</p>
<p class="desc">The number of analysability rules that have at least one violation on the artefact.</p>
</li>
                <li class="list-group-item"><p id="RKO_CHA"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of violated rules for changeability</strong> ( RKO_CHA )</p>
<p class="desc">The number of changeability rules that have at least one violation on the artefact.</p>
</li>
                <li class="list-group-item"><p id="RKO_REL"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of violated rules for reliability</strong> ( RKO_REL )</p>
<p class="desc">The number of reliability rules that have at least one violation on the artefact.</p>
</li>
                <li class="list-group-item"><p id="RKO_REU"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of violated rules for reusability</strong> ( RKO_REU )</p>
<p class="desc">The number of reusability rules that have at least one violation on the artefact.</p>
</li>
                <li class="list-group-item"><p id="ROKR_ANA"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Adherence to analysability rules</strong> ( ROKR_ANA )</p>
<p class="desc">Ratio of conform analysability practices on the number of checked analysability practices.</p>
</li>
                <li class="list-group-item"><p id="ROKR_CHA"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Adherence to changeability rules</strong> ( ROKR_CHA )</p>
<p class="desc">Ratio of conform changeability practices on the number of checked changeability practices.</p>
</li>
                <li class="list-group-item"><p id="ROKR_REL"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Adherence to reliability rules</strong> ( ROKR_REL )</p>
<p class="desc">Ratio of conform reliability practices on the number of checked reliability practices.</p>
</li>
                <li class="list-group-item"><p id="ROKR_REU"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Adherence to reusability rules</strong> ( ROKR_REU )</p>
<p class="desc">Ratio of conform reusability practices on the number of checked reusability practices.</p>
</li>
                <li class="list-group-item"><p id="RULES_ANA"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of rules for analysability</strong> ( RULES_ANA )</p>
<p class="desc">The total number of rules checked for analysability.</p>
</li>
                <li class="list-group-item"><p id="RULES_CHA"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of rules for changeability</strong> ( RULES_CHA )</p>
<p class="desc">The total number of rules checked for changeability.</p>
</li>
                <li class="list-group-item"><p id="RULES_REL"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of rules for reliability</strong> ( RULES_REL )</p>
<p class="desc">The total number of rules checked for reliability.</p>
</li>
                <li class="list-group-item"><p id="RULES_REU"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of rules for reusability</strong> ( RULES_REU )</p>
<p class="desc">The total number of rules checked for reusability.</p>
</li>
                <li class="list-group-item"><p id="SCM_COMMITS_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>SCM Commits</strong> ( SCM_COMMITS_1M )</p>
<p class="desc">Total number of commits in source code management repositories dated during the last month divided by the number of thousands of lines of code.</p>
<p class="desc">Source code management repositories are those considered as such in the project documentation. Commits in all branches are considered. Date used for each commit is 'author date' (when there is a difference between author date and committer date). Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). The number of lines are those calculated at the end of the period of analysis.</p>
</li>
                <li class="list-group-item"><p id="SCM_COMMITTED_FILES_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Files committed</strong> ( SCM_COMMITTED_FILES_1M )</p>
<p class="desc">Total number of files touched by commits in source code management repositories dated during the last month, divided by the number of thousands of lines of code.</p>
<p class="desc">Source code management repositories are those considered as such in the project documentation. Commits in all branches are considered. A file is 'touched' by a commit if its content or its path are modified by the commit. Date used for each commit is 'author date' (when there is a difference between author date and committer date). Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). Number of lines are those calculated at the end of the period of analysis.</p>
</li>
                <li class="list-group-item"><p id="SCM_COMMITTERS_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>SCM committers</strong> ( SCM_COMMITTERS_1M )</p>
<p class="desc">Total number of identities found as authors of commits in source code management repositories dated during the last month, divided by the number of thousands of lines of code.</p>
<p class="desc">Source code management repositories are those considered as such in the project documentation. Commits in all branches are considered. Date used for each commit is 'author date' (when there is a difference between author date and committer date). An identity is considered as author if it appears as such in the commit record (for systems logging several identities related to the commit, authoring identity will be considered). Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). Number of lines are those calculated at the end of the period of analysis.</p>
</li>
                <li class="list-group-item"><p id="SCM_STABILITY_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>File stability index</strong> ( SCM_STABILITY_1M )</p>
<p class="desc">Average number of commits touching each file in source code management repositories dated during the last month. </p>
<p class="desc">Source code management repositories are those considered as such in the project documentation. Commits in all branches are considered. A file is 'touched' by a commit if its content or its path are modified by the commit. Date used for each commit is 'author date' (when there is a difference between author date and committer date). Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included).</p>
</li>
                <li class="list-group-item"><p id="SLOC"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Source Lines Of Code</strong> ( SLOC )</p>
<p class="desc">Number of physical lines that contain at least one character which is neither a whitespace or a tabulation or part of a comment. This is mapped to SonarQube's <mark>ncloc</mark> metric.</p>
<p class="desc">See also SonarQube's definition for size metrics: <a href="http://docs.codehaus.org/display/SONAR/Metric+definitions#Metricdefinitions-Size">http://docs.codehaus.org/display/SONAR/Metric+definitions#Metricdefinitions-Size</a>. More details can be seen here: <a href="http://docs.codehaus.org/display/SONAR/Metrics+-+Lines+of+code">http://docs.codehaus.org/display/SONAR/Metrics+-+Lines+of+code</a></p>
</li>
                <li class="list-group-item"><p id="SURVEY_INSTALL"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Installation survey</strong> ( SURVEY_INSTALL )</p>
<p class="desc">A survey stating how much the software has been installed: number of users, geography (are the teams co-located or distributed?), etc.</p>
</li>
                <li class="list-group-item"><p id="TOPD"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Total number of operands</strong> ( TOPD )</p>
<p class="desc">The total number of operands found in the function. The measure was first introduced by Halstead in his <i>Elements of Software Sience</i> [<a href="Halstead1977">Halstead</a>]. An operand is an entity on which an operation is performed: e.g. a variable, constant, number. An operator is a construct that performs an operation: e.g. a function, concatenation, addition.</p>
<p class="desc">Useful measures derived from the set of Halstead operators include program vocabulary (<var>n</var>), program length (<var>N</var>), program volume (<var>V</var>) or estimated effort needed for program comprehension (<var>E</var>).</p>
<p class="desc">See also the Maisqual wiki: <a href="http://maisqual.squoring.com/wiki/index.php/Category:Halstead_Metrics">http://maisqual.squoring.com/wiki/index.php/Category:Halstead_Metrics</a>.</p>
</li>
                <li class="list-group-item"><p id="TOPT"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Total number of operators</strong> ( TOPT )</p>
<p class="desc">The total number of operators found in the function. The measure was first introduced by Halstead in his <i>Elements of Software Sience</i> [<a href="Halstead1977">Halstead</a>]. An operand is an entity on which an operation is performed: e.g. a variable, constant, number. An operator is a construct that performs an operation: e.g. a function, concatenation, addition.</p>
<p class="desc">Useful measures derived from the set of Halstead operators include program vocabulary (<var>n</var>), program length (<var>N</var>), program volume (<var>V</var>) or estimated effort needed for program comprehension (<var>E</var>).</p>
<p class="desc">See also the Maisqual wiki: <a href="http://maisqual.squoring.com/wiki/index.php/Category:Halstead_Metrics">http://maisqual.squoring.com/wiki/index.php/Category:Halstead_Metrics</a>.</p>
</li>
                <li class="list-group-item"><p id="TST_COV_BRANCHES"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Percentage of branches covered by tests</strong> ( TST_COV_BRANCHES )</p>
<p class="desc">The percentage of branches that is exercised by the tests.</p>
<p class="desc">On a given line of code, Line coverage simply answers the following question: Has this line of code been executed during the execution of the unit tests?</p>
</li>
                <li class="list-group-item"><p id="TST_COV_LINES"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Percentage of lines of code covered by tests</strong> ( TST_COV_LINES )</p>
<p class="desc">The percentage of source lines of code that is exercised by the tests.</p>
</li>
                <li class="list-group-item"><p id="TST_SUCCESS_LAST"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Test success density</strong> ( TST_SUCCESS_LAST )</p>
<p class="desc">The percentage of failed tests during the last execution of the test plan.</p>
<p class="desc">Computation is as follows: Test success density = (Unit tests - (Unit test errors + Unit test failures)) / Unit tests * 100, where Unit test errors is the number of unit tests that have failed, Unit test failures is the number of unit tests that have failed with an unexpected exception.</p>
</li>
                <li class="list-group-item"><p id="TST_VOL_IDX"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of tests relative to the code size</strong> ( TST_VOL_IDX )</p>
<p class="desc">The total number of test cases for the product, divided by the number of thousands of SLOC.</p>
<p class="desc">Metric is computed from SonarQube <mark>tests</mark> and <mark>ncloc</mark> metrics.</p>
</li>
                <li class="list-group-item"><p id="VG"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Average Cyclomatic Complexity</strong> ( VG )</p>
<p class="desc">The average number of execution paths found in functions.</p>
<p class="desc">Basically, the counter is incremented every time the control flow of the function splits, with any function having at least a cyclomatic number of 1. The sum of cyclomatic numbers for all functions is then divided by the number of functions. In SonarQube the measure is <code>function_complexity</code>.</p>
<p class="desc">The cyclomatic number is a measure borrowed from graph theory and was introduced to software engineering by McCabe in [<a href="/documentation/references.html">McCabe1976</a>]. It is defined as the number of linearly independent paths that comprise the program. To have good testability and maintainability, McCabe recommends that no program modules (or functions as for Java) should exceed a cyclomatic number of 10. It is primarily defined at the function level and is summed up for higher levels of artefacts.</p>
<p class="desc">See also Wikipedia's entry on cyclomatic complexity: <a href="http://en.wikipedia.org/wiki/Cyclomatic_complexity">http://en.wikipedia.org/wiki/Cyclomatic_complexity</a>.</p>
<p class="desc">See also SonarQube's definition for code complexity: <a href="http://docs.codehaus.org/display/SONAR/Metrics+-+Complexity">http://docs.codehaus.org/display/SONAR/Metrics+-+Complexity</a>. There is also a discussion about its meaning here: <a href="http://www.sonarqube.org/discussing-cyclomatic-complexity/">http://www.sonarqube.org/discussing-cyclomatic-complexity/</a></p>
<p class="desc">See also the Maisqual wiki for more details on complexity measures: <a href="http://maisqual.squoring.com/wiki/index.php/Category:Complexity_Metrics">http://maisqual.squoring.com/wiki/index.php/Category:Complexity_Metrics</a>.</p>
</li>
                  </ul></div>
                  <div role="tabpanel" class="tab-pane fade" id="repo_Grimoire"><br />
                    <ul class="list-group">
                      <li class="list-group-item"><p id="ITS_AUTH_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>ITS authors</strong> ( ITS_AUTH_1M )</p>
<p class="desc">Number of distinct identities updating tickets during the last month, in the issue tracking system, divided by the number of thousands of lines of code.</p>
<p class="desc">The subset of tickets considered from the issue tracking system are those specified in the project documentation, for example by specifying a tracker or a project name appearing in ticket data. Update means an operation on a ticket changing its state, or adding information. Opening and closing a ticket are considered as updates. Identities of updaters are the character strings found in the corresponding field in the ticket information. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). Number of lines are those calculated at the end of the period of analysis.</p>
</li>
                      <li class="list-group-item"><p id="ITS_BUGS_DENSITY"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Defect density</strong> ( ITS_BUGS_DENSITY )</p>
<p class="desc">Ratio of the total number of tickets in the issue tracking system to the size of the source code in KLOC, at the time of the data retrieval. </p>
<p class="desc">The subset of tickets considered from the issue tracking system are those specified in the project documentation, for example by specifying a tracker or a project name appearing in ticket data. Source code is all source code found in the source code management repository.</p>
</li>
                      <li class="list-group-item"><p id="ITS_BUGS_OPEN"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of open bugs</strong> ( ITS_BUGS_OPEN )</p>
<p class="desc">Number of tickets marked as still open at the time of the data retrieval, in the issue tracking system, divided by the number of thousands of lines of code.</p>
<p class="desc">The subset of tickets considered from the issue tracking system are those specified in the project documentation, for example by specifying a tracker or a project name appearing in ticket data. Open means the state in which further actions are usually expected until the ticket is closed. Number of lines are those calculated at the end of the period of analysis.</p>
</li>
                      <li class="list-group-item"><p id="ITS_FIX_MED_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Median time to fix bug</strong> ( ITS_FIX_MED_1M )</p>
<p class="desc">Median period from when a ticket is open to when a ticket is closed, for all tickets closed during the last month, in the issue tracking system. </p>
<p class="desc">The subset of tickets considered from the issue tracking system are those specified in the project documentation, for example by specifying a tracker or a project name appearing in ticket data. Closed means the state in which no further action is usually performed in the ticket. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). Unit is days.</p>
</li>
                      <li class="list-group-item"><p id="ITS_ISSUES_OPENERS_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of issue openers during last month</strong> ( ITS_ISSUES_OPENERS_1M )</p>
<p class="desc">Number of distinct identities opening tickets during the last month, in the issue tracking system, divided by the number of thousands of lines of code.</p>
<p class="desc">The subset of tickets considered from the issue tracking system are those specified in the project documentation, for example by specifying a tracker or a project name appearing in ticket data. Opened means that the ticket information was submitted to the issue traking system for the first time for that ticket. Identities of openers are the character strings found in the corresponding field in the ticket information. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). Number of lines are those calculated at the end of the period of analysis.</p>
</li>
                      <li class="list-group-item"><p id="ITS_ISSUES_OPEN_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of issues opened during last month</strong> ( ITS_ISSUES_OPEN_1M )</p>
<p class="desc">Number of tickets opened (new) during the last month, in the issue tracking system out, divided by the number of thousands of lines of code</p>
<p class="desc">The subset of tickets considered from the issue tracking system are those specified in the project documentation, for example by specifying a tracker or a project name appearing in ticket data. Opened means that the ticket information was submitted to the issue traking system for the first time for that ticket. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). Number of lines are those calculated at the end of the period of analysis.</p>
</li>
                      <li class="list-group-item"><p id="ITS_UPDATES_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>ITS updates</strong> ( ITS_UPDATES_1M )</p>
<p class="desc">Number of updates to tickets during the last month, in the issue tracking system, divided by the number of thousands of lines of code.</p>
<p class="desc">The subset of tickets considered from the issue tracking system are those specified in the project documentation, for example by specifying a tracker or a project name appearing in ticket data. Update means an operation on a ticket changing its state, or adding information. Opening and closing a ticket are considered as updates. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). Number of lines are those calculated at the end of the period of analysis.</p>
</li>
                      <li class="list-group-item"><p id="MLS_DEV_AUTH_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Developer ML authors</strong> ( MLS_DEV_AUTH_1M )</p>
<p class="desc">Number of distinct senders for messages dated during the last month, in developer mailing list archives, divided by the number of thousands of lines of code. </p>
<p class="desc">Developer mailing list is the list or lists considered as 'for developers' in the project documentation. The date used is the mailing list server date, as stamped in the message. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). Distinct senders are those with distinct email addresses. Email addresses used are the strings found in 'From:' fields in messages. The number of lines are those calculated at the end of the period of analysis.</p>
</li>
                      <li class="list-group-item"><p id="MLS_DEV_RESP_RATIO_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Developer ML response ratio</strong> ( MLS_DEV_RESP_RATIO_1M )</p>
<p class="desc">Average number of messages in thread, minus one, for all threds of messages dated during the last month, in developer mailing list archives. </p>
<p class="desc">Threads are identified using 'In-Reply-To' message headers. Developer mailing list is the list or lists considered as 'for developers' in the project documentation. The date used is the mailing list server date, as stamped in the message. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included).</p>
</li>
                      <li class="list-group-item"><p id="MLS_DEV_RESP_TIME_MED_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Developer ML response time</strong> ( MLS_DEV_RESP_TIME_MED_1M )</p>
<p class="desc">Median period from first message in thread to second message in thread, for all threds with at least two messages dated during the last month, in developer mailing list archives. </p>
<p class="desc">Threads are identified using 'In-Reply-To' message headers. Developer mailing list is the list or lists considered as 'for developers' in the project documentation. The date used is the mailing list server date, as stamped in the message. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). Unit is days.</p>
</li>
                      <li class="list-group-item"><p id="MLS_DEV_SUBJ_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Developer ML subjects</strong> ( MLS_DEV_SUBJ_1M )</p>
<p class="desc">Number of threds of messages dated during the last month, in developer mailing list archives, divided by the number of thousands of lines of code. </p>
<p class="desc">Threads are identified using 'In-Reply-To' message headers. Developer mailing list is the list or lists considered as 'for developers' in the project documentation. The date used is the mailing list server date, as stamped in the message. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). The number of lines are those calculated at the end of the period of analysis.</p>
</li>
                      <li class="list-group-item"><p id="MLS_DEV_VOL_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Developer ML posts</strong> ( MLS_DEV_VOL_1M )</p>
<p class="desc">Number of messages dated during the last month, in developer mailing list archives, divided by the number of thousands of lines of code.</p>
<p class="desc">Developer mailing list is the list or lists considered as 'for developers' in the project documentation. The date used is the mailing list server date, as stamped in the message. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). The number of lines are those calculated at the end of the period of analysis.</p>
</li>
                      <li class="list-group-item"><p id="MLS_USR_AUTH_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>User ML authors</strong> ( MLS_USR_AUTH_1M )</p>
<p class="desc">Number of distinct senders for messages dated during the last month, in user mailing list archives, divided by the number of thousands of lines of code.</p>
<p class="desc">User mailing list is the list or lists considered as 'for users' in the project documentation. The date used is the mailing list server date, as stamped in the message. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). Distinct senders are those with distinct email addresses. Email addresses used are the strings found in 'From:' fields in messages. The number of lines are those calculated at the end of the period of analysis.</p>
</li>
                      <li class="list-group-item"><p id="MLS_USR_RESP_RATIO_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>User ML response ratio</strong> ( MLS_USR_RESP_RATIO_1M )</p>
<p class="desc">Average number of messages in thread, minus one, for all threds of messages dated during the last month, in user mailing list archives. </p>
<p class="desc">Threads are identified using 'In-Reply-To' message headers. User mailing list is the list or lists considered as 'for users' in the project documentation. The date used is the mailing list server date, as stamped in the message. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included).</p>
</li>
                      <li class="list-group-item"><p id="MLS_USR_RESP_TIME_MED_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>User ML response time</strong> ( MLS_USR_RESP_TIME_MED_1M )</p>
<p class="desc">Median period from first message in thread to second message in thread, for all threds with at least two messages dated during the last month, in user mailing list archives. </p>
<p class="desc">Threads are identified using 'In-Reply-To' message headers. User mailing list is the list or lists considered as 'for users' in the project documentation. The date used is the mailing list server date, as stamped in the message. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). Unit is days.</p>
</li>
                      <li class="list-group-item"><p id="MLS_USR_SUBJ_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>User ML subjects</strong> ( MLS_USR_SUBJ_1M )</p>
<p class="desc">Number of threds of messages dated during the last month, in user mailing list archives, divided by the number of thousands of lines of code.</p>
<p class="desc">Threads are identified using 'In-Reply-To' message headers. User mailing list is the list or lists considered as 'for users' in the project documentation. The date used is the mailing list server date, as stamped in the message. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). The number of lines are those calculated at the end of the period of analysis.</p>
</li>
                      <li class="list-group-item"><p id="MLS_USR_VOL_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>User ML posts</strong> ( MLS_USR_VOL_1M )</p>
<p class="desc">Number of messages dated during the last month, in user mailing list archives, divided by the number of thousands of lines of code. </p>
<p class="desc">User mailing list is the list or lists considered as 'for users' in the project documentation. The date used is the mailing list server date, as stamped in the message. Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). The number of lines are those calculated at the end of the period of analysis.</p>
</li>
                      <li class="list-group-item"><p id="SCM_COMMITS_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>SCM Commits</strong> ( SCM_COMMITS_1M )</p>
<p class="desc">Total number of commits in source code management repositories dated during the last month divided by the number of thousands of lines of code.</p>
<p class="desc">Source code management repositories are those considered as such in the project documentation. Commits in all branches are considered. Date used for each commit is 'author date' (when there is a difference between author date and committer date). Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). The number of lines are those calculated at the end of the period of analysis.</p>
</li>
                      <li class="list-group-item"><p id="SCM_COMMITTED_FILES_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Files committed</strong> ( SCM_COMMITTED_FILES_1M )</p>
<p class="desc">Total number of files touched by commits in source code management repositories dated during the last month, divided by the number of thousands of lines of code.</p>
<p class="desc">Source code management repositories are those considered as such in the project documentation. Commits in all branches are considered. A file is 'touched' by a commit if its content or its path are modified by the commit. Date used for each commit is 'author date' (when there is a difference between author date and committer date). Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). Number of lines are those calculated at the end of the period of analysis.</p>
</li>
                      <li class="list-group-item"><p id="SCM_COMMITTERS_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>SCM committers</strong> ( SCM_COMMITTERS_1M )</p>
<p class="desc">Total number of identities found as authors of commits in source code management repositories dated during the last month, divided by the number of thousands of lines of code.</p>
<p class="desc">Source code management repositories are those considered as such in the project documentation. Commits in all branches are considered. Date used for each commit is 'author date' (when there is a difference between author date and committer date). An identity is considered as author if it appears as such in the commit record (for systems logging several identities related to the commit, authoring identity will be considered). Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included). Number of lines are those calculated at the end of the period of analysis.</p>
</li>
                      <li class="list-group-item"><p id="SCM_STABILITY_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>File stability index</strong> ( SCM_STABILITY_1M )</p>
<p class="desc">Average number of commits touching each file in source code management repositories dated during the last month. </p>
<p class="desc">Source code management repositories are those considered as such in the project documentation. Commits in all branches are considered. A file is 'touched' by a commit if its content or its path are modified by the commit. Date used for each commit is 'author date' (when there is a difference between author date and committer date). Last month is measured as one calendar month period starting the day before the data retrieval (example: if retrival is on Feb 3rd, period is from Jan 3rd to Feb 2nd, both included).</p>
</li>
                    </ul>
                  </div>  
                  <div role="tabpanel" class="tab-pane fade" id="repo_Manual"><br />
                    <ul class="list-group">
                      <li class="list-group-item"><p id="PUB_CONF_VOL"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of publications</strong> ( PUB_CONF_VOL )</p>
<p class="desc">The number of papers published in conferences, journals, and public web sites.</p>
<p class="desc">This metric is not yet active because its retrieval is being debated.</p>
</li>
                      <li class="list-group-item"><p id="SURVEY_INSTALL"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Installation survey</strong> ( SURVEY_INSTALL )</p>
<p class="desc">A survey stating how much the software has been installed: number of users, geography (are the teams co-located or distributed?), etc.</p>
</li>
                    </ul>
                  </div>  
                  <div role="tabpanel" class="tab-pane fade" id="repo_MarketplaceScript"><br />
                    <ul class="list-group">
                      <li class="list-group-item"><p id="MKT_FAV"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of favourites on the Marketplace</strong> ( MKT_FAV )</p>
<p class="desc">The number of favourites on the Eclipse Marketplace for the project.</p>
<p class="desc">This measure uses the MarketPlace REST API to retrieve the number of registered users who marked this project as a favourite. If the project is not registered on the Marketplace, the metric should be zero.</p>
</li>
                      <li class="list-group-item"><p id="MKT_INSTALL_FAILED_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of failed install on the Marketplace</strong> ( MKT_INSTALL_FAILED_1M )</p>
<p class="desc">The number of failed installs for the project as reported on the Marketplace during the last month.</p>
<p class="desc">THis measure uses the list of failed installs available on the Marketplace for every registered project. Here is <a href="http://marketplace.eclipse.org/unsuccessful/installs/1373403/error_report.csv">an example of log page</a>, errors tab. If the project is not registered on the Marketplace, the metric should be zero.</p>
</li>
                      <li class="list-group-item"><p id="MKT_INSTALL_SUCCESS_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of successfull installs on the Marketplace</strong> ( MKT_INSTALL_SUCCESS_1M )</p>
<p class="desc">The number of successful installs for the project as reported on the Marketplace during the last month.</p>
<p class="desc">This measure uses the list of successful installs available on the Marketplace for every registered project. Here is <a href="http://marketplace.eclipse.org/content/eclipse-cdt-cc-development-tooling">an example of log page</a>, metrics tab. If the project is not registered on the Marketplace, the metric should be zero.</p>
</li>
                    </ul>
                  </div>  
                  <div role="tabpanel" class="tab-pane fade" id="repo_PMI"><br />
                    <ul class="list-group">
                      <li class="list-group-item"><p id="PLAN_MILESTONES_VOL_1Y"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of milestones</strong> ( PLAN_MILESTONES_VOL_1Y )</p>
<p class="desc">The number of milestones that occured during the last year.</p>
<p class="desc">Milestones are retrieved from the PMI file and are counted whatever their target release is. Milestones are useful to assess the maturity of the release and improves predictability of the project's output, in terms of quality and time.</p>
</li>
                      <li class="list-group-item"><p id="PLAN_NEXT_MILESTONE"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Project is on time for next milestone</strong> ( PLAN_NEXT_MILESTONE )</p>
<p class="desc">Is the project on time for the next milestone?</p>
</li>
                      <li class="list-group-item"><p id="PLAN_REVIEWS_SUCCESS_RATE"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Milestone success rate</strong> ( PLAN_REVIEWS_SUCCESS_RATE )</p>
<p class="desc">What is the percentage of successful reviews over the past 5 releases?</p>
<p class="desc">The reviews are retrieved from the project management infrastructure record, and are considered successful if the entry is equal to <mark>success</mark>. If there are less than 5 releases defined, the percentage is computed on these only.</p>
</li>
                      <li class="list-group-item"><p id="PUB_ITS_INFO_PMI"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>ITS information</strong> ( PUB_ITS_INFO_PMI )</p>
<p class="desc">Is the bugzilla info correctly filled in the PMI records?</p>
<p class="desc">The project management infrastructure file holds information about one or more bugzilla instances. This test checks that at least one bugzilla instance is defined, with a product identifier, a create_url to enter a new issue, and a query_url to fetch all the issues for the project.</p>
</li>
                      <li class="list-group-item"><p id="PUB_SCM_INFO_PMI"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>SCM information</strong> ( PUB_SCM_INFO_PMI )</p>
<p class="desc">Is the source_repo info correctly filled in the PMI records? </p>
<p class="desc">The project management infrastructure file holds information about one or more source repositories. This test checks that at least one source repository is defined, and accessible.</p>
</li>
                    </ul>
                  </div>  
                  <div role="tabpanel" class="tab-pane fade" id="repo_RuleCheckingScript"><br />
                    <ul class="list-group">
                      <li class="list-group-item"><p id="NCC_ANA"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of non-conformities for analysability</strong> ( NCC_ANA )</p>
<p class="desc">The total number of violations of rules that impact analysability in the source code.</p>
<p class="desc">See also the <a href="/documentation/rules.html">page on practices</a> for a list of checked rules and their associated impact on quality characteristics.</p>
</li>
                      <li class="list-group-item"><p id="NCC_ANA_IDX"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Average number of non-conformities for analysability</strong> ( NCC_ANA_IDX )</p>
<p class="desc">The total number of violations of rules that impact analysability in the source code, divided by the number of thousands of lines of code.</p>
<p class="desc">See also the <a href="/documentation/rules.html">page on practices</a> for a list of checked rules and their associated impact on quality characteristics.</p>
</li>
                      <li class="list-group-item"><p id="NCC_CHA"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of non-conformities for changeability</strong> ( NCC_CHA )</p>
<p class="desc">The total number of violations of rules that impact changeability in the source code.</p>
<p class="desc">See also the <a href="/documentation/rules.html">page on practices</a> for a list of checked rules and their associated impact on quality characteristics.</p>
</li>
                      <li class="list-group-item"><p id="NCC_CHA_IDX"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Average number of non-conformities for changeability</strong> ( NCC_CHA_IDX )</p>
<p class="desc">The total number of violations of rules that impact changeability in the source code, divided by the number of thousands of lines of code.</p>
<p class="desc">See also the <a href="/documentation/rules.html">page on practices</a> for a list of checked rules and their associated impact on quality characteristics.</p>
</li>
                      <li class="list-group-item"><p id="NCC_REL"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of non-conformities for reliability</strong> ( NCC_REL )</p>
<p class="desc">The total number of violations of rules that impact reliability in the source code.</p>
<p class="desc">See also the <a href="/documentation/rules.html">page on practices</a> for a list of checked rules and their associated impact on quality characteristics.</p>
</li>
                      <li class="list-group-item"><p id="NCC_REL_IDX"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Average number of non-conformities for reliability</strong> ( NCC_REL_IDX )</p>
<p class="desc">The total number of violations of rules that impact reliability in the source code, divided by the number of thousands of lines of code.</p>
<p class="desc">See also the <a href="/documentation/rules.html">page on practices</a> for a list of checked rules and their associated impact on quality characteristics.</p>
</li>
                      <li class="list-group-item"><p id="NCC_REU"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of non-conformities for reusability</strong> ( NCC_REU )</p>
<p class="desc">The total number of violations of rules that impact reusability in the source code.</p>
<p class="desc">See also the <a href="/documentation/rules.html">page on practices</a> for a list of checked rules and their associated impact on quality characteristics.</p>
</li>
                      <li class="list-group-item"><p id="NCC_REU_IDX"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Average number of non-conformities for reusability</strong> ( NCC_REU_IDX )</p>
<p class="desc">The total number of violations of rules that impact reusability in the source code, divided by the number of thousands of lines of code.</p>
<p class="desc">See also the <a href="/documentation/rules.html">page on practices</a> for a list of checked rules and their associated impact on quality characteristics.</p>
</li>
                      <li class="list-group-item"><p id="RKO_ANA"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of violated rules for analysability</strong> ( RKO_ANA )</p>
<p class="desc">The number of analysability rules that have at least one violation on the artefact.</p>
</li>
                      <li class="list-group-item"><p id="RKO_CHA"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of violated rules for changeability</strong> ( RKO_CHA )</p>
<p class="desc">The number of changeability rules that have at least one violation on the artefact.</p>
</li>
                      <li class="list-group-item"><p id="RKO_REL"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of violated rules for reliability</strong> ( RKO_REL )</p>
<p class="desc">The number of reliability rules that have at least one violation on the artefact.</p>
</li>
                      <li class="list-group-item"><p id="RKO_REU"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of violated rules for reusability</strong> ( RKO_REU )</p>
<p class="desc">The number of reusability rules that have at least one violation on the artefact.</p>
</li>
                      <li class="list-group-item"><p id="ROKR_ANA"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Adherence to analysability rules</strong> ( ROKR_ANA )</p>
<p class="desc">Ratio of conform analysability practices on the number of checked analysability practices.</p>
</li>
                      <li class="list-group-item"><p id="ROKR_CHA"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Adherence to changeability rules</strong> ( ROKR_CHA )</p>
<p class="desc">Ratio of conform changeability practices on the number of checked changeability practices.</p>
</li>
                      <li class="list-group-item"><p id="ROKR_REL"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Adherence to reliability rules</strong> ( ROKR_REL )</p>
<p class="desc">Ratio of conform reliability practices on the number of checked reliability practices.</p>
</li>
                      <li class="list-group-item"><p id="ROKR_REU"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Adherence to reusability rules</strong> ( ROKR_REU )</p>
<p class="desc">Ratio of conform reusability practices on the number of checked reusability practices.</p>
</li>
                      <li class="list-group-item"><p id="RULES_ANA"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of rules for analysability</strong> ( RULES_ANA )</p>
<p class="desc">The total number of rules checked for analysability.</p>
</li>
                      <li class="list-group-item"><p id="RULES_CHA"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of rules for changeability</strong> ( RULES_CHA )</p>
<p class="desc">The total number of rules checked for changeability.</p>
</li>
                      <li class="list-group-item"><p id="RULES_REL"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of rules for reliability</strong> ( RULES_REL )</p>
<p class="desc">The total number of rules checked for reliability.</p>
</li>
                      <li class="list-group-item"><p id="RULES_REU"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of rules for reusability</strong> ( RULES_REU )</p>
<p class="desc">The total number of rules checked for reusability.</p>
</li>
                    </ul>
                  </div>  
                  <div role="tabpanel" class="tab-pane fade" id="repo_SonarQube"><br />
                    <ul class="list-group">
                      <li class="list-group-item"><p id="ATTRS"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Average number of attributes</strong> ( ATTRS )</p>
<p class="desc">Average number of attributes defined in a class. This can be compared to the <a href="/documentation/metrics.html#TOPD">total number of operands</a> (TOPD) considered at the class level, and is representative of the data complexity of the class (not including the complexity of methods).</p>
</li>
                      <li class="list-group-item"><p id="ATTRS_PUBLIC"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Average number of public attributes</strong> ( ATTRS_PUBLIC )</p>
<p class="desc">Average number of attributes defined in classes with a <code>public</code> modifier.</p>
<p class="desc">Publicness of attributes is meaningful for reusability: if there are a lot of public attributes available, it may be more time-consuming to find the right one. Also, good practices for object-oriented programming recommend to use getters and setters in most cases.</p>
</li>
                      <li class="list-group-item"><p id="CLASSES"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of classes</strong> ( CLASSES )</p>
<p class="desc">The number of Java classes, including nested classes, interfaces, enums and annotations.</p>
<p class="desc">The SonarQube measure used for this purpose is <mark>classes</mark>. This metric is often used as rule-of-thumb indicator for the size of software, and to make other measures relatives.</p>
<p class="desc">See also SonarQube's definitions for size metrics: <a href="http://docs.codehaus.org/display/SONAR/Metric+definitions#Metricdefinitions-Size">http://docs.codehaus.org/display/SONAR/Metric+definitions#Metricdefinitions-Size</a>.</p>
</li>
                      <li class="list-group-item"><p id="CLONE_IDX"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Cloning density</strong> ( CLONE_IDX )</p>
<p class="desc">The amount of duplicated lines in the code, divided by the number of lines. The SonarQube metric used for this purpose is <mark>duplicated_lines_density</mark>.</p>
<p class="desc">See also SonarQube's definition for duplications: <a href="http://docs.codehaus.org/display/SONAR/Metric+definitions#Metricdefinitions-Duplications">http://docs.codehaus.org/display/SONAR/Metric+definitions#Metricdefinitions-Duplications</a>. There is a longer description of the code cloning algorithm here: <a href="http://docs.codehaus.org/display/SONAR/Duplications">http://docs.codehaus.org/display/SONAR/Duplications</a>.</p>
</li>
                      <li class="list-group-item"><p id="COMR"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Comment rate</strong> ( COMR )</p>
<p class="desc">The ratio of source lines of code on the number of comment lines of code.</p>
<p class="desc">Density of comment lines = Comment lines / (Lines of code + Comment lines) * 100. With such a formula, <var>50%</var> means that the number of lines of code equals the number of comment lines and <var>100%</var> means that the file only contains comment lines. The SonarQube measure used for this purpose is <mark>comment_lines_density</mark>. </p>
<p class="desc">See also SonarQube's page on comment lines metrics: <a href="http://docs.codehaus.org/display/SONAR/Metrics+-+Comment+lines">http://docs.codehaus.org/display/SONAR/Metrics+-+Comment+lines</a>.</p>
</li>
                      <li class="list-group-item"><p id="DOPD"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of distinct operands</strong> ( DOPD )</p>
<p class="desc">The number of distinct operands found in the function. The measure was first introduced by Halstead in his <i>Elements of Software Sience</i> [<a href="Halstead1977">Halstead</a>]. An operand is an entity on which an operation is performed: e.g. a variable, constant, number. An operator is a construct that performs an operation: e.g. a function, concatenation, addition.</p>
<p class="desc">Useful measures derived from the set of Halstead operators include program vocabulary (<var>n</var>), program length (<var>N</var>), program volume (<var>V</var>) or estimated effort needed for program comprehension (<var>E</var>).</p>
<p class="desc">See also the Maisqual wiki: <a href="http://maisqual.squoring.com/wiki/index.php/Category:Halstead_Metrics">http://maisqual.squoring.com/wiki/index.php/Category:Halstead_Metrics</a>.</p>
</li>
                      <li class="list-group-item"><p id="DOPT"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of distinct operators</strong> ( DOPT )</p>
<p class="desc">The number of distinct operators found in the function. The measure was first introduced by Halstead in his <i>Elements of Software Sience</i> [<a href="Halstead1977">Halstead</a>]. An operand is an entity on which an operation is performed: e.g. a variable, constant, number. An operator is a construct that performs an operation: e.g. a function, concatenation, addition.</p>
<p class="desc">Useful measures derived from the set of Halstead operators include program vocabulary (<var>n</var>), program length (<var>N</var>), program volume (<var>V</var>) or estimated effort needed for program comprehension (<var>E</var>).</p>
<p class="desc">See also the Maisqual wiki: <a href="http://maisqual.squoring.com/wiki/index.php/Category:Halstead_Metrics">http://maisqual.squoring.com/wiki/index.php/Category:Halstead_Metrics</a>.</p>
</li>
                      <li class="list-group-item"><p id="FILES"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of files</strong> ( FILES )</p>
<p class="desc">The number of code files (e.g. with a <code>.java</code> for the Java language) in the source code hierarchy. The SonarQube measure used for this purpose is <mark>files</mark>. This metric is often used as rule-of-thumb indicator for the size of software, and to make other measures relatives.</p>
</li>
                      <li class="list-group-item"><p id="FUNCTIONS"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of functions</strong> ( FUNCTIONS )</p>
<p class="desc">The number of functions defined in the source files.</p>
<p class="desc">The SonarQube measure used for this purpose is <mark>functions</mark>. This metric is often used as rule-of-thumb indicator for the size of software, and to make other measures relatives.</p>
<p class="desc">See also SonarQube's definitions for size metrics: <a href="http://docs.codehaus.org/display/SONAR/Metric+definitions#Metricdefinitions-Size">http://docs.codehaus.org/display/SONAR/Metric+definitions#Metricdefinitions-Size</a>. More details on the metric: <a href="http://docs.codehaus.org/display/SONAR/Metrics+-+Methods">http://docs.codehaus.org/display/SONAR/Metrics+-+Methods</a>.</p>
</li>
                      <li class="list-group-item"><p id="MDIT"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Depth of Inheritance Tree</strong> ( MDIT )</p>
<p class="desc">The maximum depth of inheritance tree of a class within the inheritance hierarchy is defined as the maximum length from the considered class to the root of the class hierarchy tree and is measured by the number of ancestor classes. In cases involving multiple inheritance, the MDIT is the maximum length from the node to the root of the tree [<a href="/documentation/references.html#Chidamber1994">Chidamber1994</a>].</p>
<p class="desc">A deep inheritance tree makes the understanding of the object-oriented architecture difficult. Well structured OO systems have a forest of classes rather than one large inheritance lattice. The deeper the class is within the hierarchy, the greater the number of methods it is likely to inherit, making it more complex to predict its behavior and, therefore, more fault-prone [<a href="/documentation/references.html#Chidamber1994">Chidamber1994</a>]. However, the deeper a particular tree is in a class, the greater potential reuse of inherited methods [<a href="/documentation/references.html#Chidamber1994">Chidamber1994</a>].</p>
<p class="desc">See also SonarQube's page on the depth in tree: <a href="http://docs.codehaus.org/display/SONAR/Metrics+-+Depth+in+Tree">http://docs.codehaus.org/display/SONAR/Metrics+-+Depth+in+Tree</a></p>
</li>
                      <li class="list-group-item"><p id="METHS"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Average number of methods</strong> ( METHS )</p>
<p class="desc">Average number of methods defined in the class. This can be compared to the <a href="/documentation/metrics.html#TOPD">total number of operators</a> (TOPT) considered at the class level.</p>
</li>
                      <li class="list-group-item"><p id="METHS_PUBLIC"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Average number of public methods</strong> ( METHS_PUBLIC )</p>
<p class="desc">Average number of methods defined in classes with a <code>public</code> modifier.</p>
<p class="desc">Publicness of methods is meaningful for reusability: if there are a lot of public methods available, it may be more time-consuming to find the right one.</p>
</li>
                      <li class="list-group-item"><p id="NEST"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Maximum depth of nesting</strong> ( NEST )</p>
<p class="desc">The maximum depth of nesting counts the highest number of imbricated code (including conditions and loops) in a function. </p>
<p class="desc">Deeper nesting threatens understandability of code and induces more test cases to run the different branches. Practitioners usually consider that a function with three or more nested levels becomes significantly more difficult for the human mind to apprehend how it works.</p>
</li>
                      <li class="list-group-item"><p id="PUBLIC_API"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Public API</strong> ( PUBLIC_API )</p>
<p class="desc">Number of public Classes + number of public Functions + number of public Properties. The SonarQube measure used for this purpose is <mark>public_api</mark>.</p>
<p class="desc">See also SonarQube's definition for size metrics: <a href="http://docs.codehaus.org/display/SONAR/Metric+definitions#Metricdefinitions-Size">http://docs.codehaus.org/display/SONAR/Metric+definitions#Metricdefinitions-Size</a>. More details can be seen here: <a href="http://docs.codehaus.org/display/SONAR/Metrics+-+Public+API">http://docs.codehaus.org/display/SONAR/Metrics+-+Public+API</a></p>
</li>
                      <li class="list-group-item"><p id="PUBLIC_API_DOC"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Public documented API</strong> ( PUBLIC_API_DOC )</p>
<p class="desc">The percentage of documented API accesses. Density of public documented API = (Public API - Public undocumented API) / Public API * 100. The SonarQube measure used for this purpose is <mark>public_documented_api_density</mark>.</p>
<p class="desc">See also SonarQube's definition for size metrics: <a href="http://docs.codehaus.org/display/SONAR/Metric+definitions#Metricdefinitions-Size">http://docs.codehaus.org/display/SONAR/Metric+definitions#Metricdefinitions-Size</a>. </p>
</li>
                      <li class="list-group-item"><p id="SLOC"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Source Lines Of Code</strong> ( SLOC )</p>
<p class="desc">Number of physical lines that contain at least one character which is neither a whitespace or a tabulation or part of a comment. This is mapped to SonarQube's <mark>ncloc</mark> metric.</p>
<p class="desc">See also SonarQube's definition for size metrics: <a href="http://docs.codehaus.org/display/SONAR/Metric+definitions#Metricdefinitions-Size">http://docs.codehaus.org/display/SONAR/Metric+definitions#Metricdefinitions-Size</a>. More details can be seen here: <a href="http://docs.codehaus.org/display/SONAR/Metrics+-+Lines+of+code">http://docs.codehaus.org/display/SONAR/Metrics+-+Lines+of+code</a></p>
</li>
                      <li class="list-group-item"><p id="TOPD"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Total number of operands</strong> ( TOPD )</p>
<p class="desc">The total number of operands found in the function. The measure was first introduced by Halstead in his <i>Elements of Software Sience</i> [<a href="Halstead1977">Halstead</a>]. An operand is an entity on which an operation is performed: e.g. a variable, constant, number. An operator is a construct that performs an operation: e.g. a function, concatenation, addition.</p>
<p class="desc">Useful measures derived from the set of Halstead operators include program vocabulary (<var>n</var>), program length (<var>N</var>), program volume (<var>V</var>) or estimated effort needed for program comprehension (<var>E</var>).</p>
<p class="desc">See also the Maisqual wiki: <a href="http://maisqual.squoring.com/wiki/index.php/Category:Halstead_Metrics">http://maisqual.squoring.com/wiki/index.php/Category:Halstead_Metrics</a>.</p>
</li>
                      <li class="list-group-item"><p id="TOPT"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Total number of operators</strong> ( TOPT )</p>
<p class="desc">The total number of operators found in the function. The measure was first introduced by Halstead in his <i>Elements of Software Sience</i> [<a href="Halstead1977">Halstead</a>]. An operand is an entity on which an operation is performed: e.g. a variable, constant, number. An operator is a construct that performs an operation: e.g. a function, concatenation, addition.</p>
<p class="desc">Useful measures derived from the set of Halstead operators include program vocabulary (<var>n</var>), program length (<var>N</var>), program volume (<var>V</var>) or estimated effort needed for program comprehension (<var>E</var>).</p>
<p class="desc">See also the Maisqual wiki: <a href="http://maisqual.squoring.com/wiki/index.php/Category:Halstead_Metrics">http://maisqual.squoring.com/wiki/index.php/Category:Halstead_Metrics</a>.</p>
</li>
                      <li class="list-group-item"><p id="TST_COV_BRANCHES"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Percentage of branches covered by tests</strong> ( TST_COV_BRANCHES )</p>
<p class="desc">The percentage of branches that is exercised by the tests.</p>
<p class="desc">On a given line of code, Line coverage simply answers the following question: Has this line of code been executed during the execution of the unit tests?</p>
</li>
                      <li class="list-group-item"><p id="TST_COV_LINES"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Percentage of lines of code covered by tests</strong> ( TST_COV_LINES )</p>
<p class="desc">The percentage of source lines of code that is exercised by the tests.</p>
</li>
                      <li class="list-group-item"><p id="TST_SUCCESS_LAST"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Test success density</strong> ( TST_SUCCESS_LAST )</p>
<p class="desc">The percentage of failed tests during the last execution of the test plan.</p>
<p class="desc">Computation is as follows: Test success density = (Unit tests - (Unit test errors + Unit test failures)) / Unit tests * 100, where Unit test errors is the number of unit tests that have failed, Unit test failures is the number of unit tests that have failed with an unexpected exception.</p>
</li>
                      <li class="list-group-item"><p id="TST_VOL_IDX"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of tests relative to the code size</strong> ( TST_VOL_IDX )</p>
<p class="desc">The total number of test cases for the product, divided by the number of thousands of SLOC.</p>
<p class="desc">Metric is computed from SonarQube <mark>tests</mark> and <mark>ncloc</mark> metrics.</p>
</li>
                      <li class="list-group-item"><p id="VG"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Average Cyclomatic Complexity</strong> ( VG )</p>
<p class="desc">The average number of execution paths found in functions.</p>
<p class="desc">Basically, the counter is incremented every time the control flow of the function splits, with any function having at least a cyclomatic number of 1. The sum of cyclomatic numbers for all functions is then divided by the number of functions. In SonarQube the measure is <code>function_complexity</code>.</p>
<p class="desc">The cyclomatic number is a measure borrowed from graph theory and was introduced to software engineering by McCabe in [<a href="/documentation/references.html">McCabe1976</a>]. It is defined as the number of linearly independent paths that comprise the program. To have good testability and maintainability, McCabe recommends that no program modules (or functions as for Java) should exceed a cyclomatic number of 10. It is primarily defined at the function level and is summed up for higher levels of artefacts.</p>
<p class="desc">See also Wikipedia's entry on cyclomatic complexity: <a href="http://en.wikipedia.org/wiki/Cyclomatic_complexity">http://en.wikipedia.org/wiki/Cyclomatic_complexity</a>.</p>
<p class="desc">See also SonarQube's definition for code complexity: <a href="http://docs.codehaus.org/display/SONAR/Metrics+-+Complexity">http://docs.codehaus.org/display/SONAR/Metrics+-+Complexity</a>. There is also a discussion about its meaning here: <a href="http://www.sonarqube.org/discussing-cyclomatic-complexity/">http://www.sonarqube.org/discussing-cyclomatic-complexity/</a></p>
<p class="desc">See also the Maisqual wiki for more details on complexity measures: <a href="http://maisqual.squoring.com/wiki/index.php/Category:Complexity_Metrics">http://maisqual.squoring.com/wiki/index.php/Category:Complexity_Metrics</a>.</p>
</li>
                    </ul>
                  </div>  
                  <div role="tabpanel" class="tab-pane fade" id="repo_Unknown"><br />
                    <ul class="list-group">
                      <li class="list-group-item"><p id="DL_REPO_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of downloads on the web site</strong> ( DL_REPO_1M )</p>
<p class="desc">The number of downloads on the web site of the project (download page) during last month. Example of download page (for CDT) : http://www.eclipse.org/downloads/ .</p>
</li>
                      <li class="list-group-item"><p id="DL_UPDATE_SITE_1M"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>Number of downloads on update site</strong> ( DL_UPDATE_SITE_1M )</p>
<p class="desc">The number of downloads on the update site of the project during last month. Is computed using successful and failed installs from marketplace.</p>
</li>
                      <li class="list-group-item"><p id="IP_LOG_COV"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>IP log code coverage</strong> ( IP_LOG_COV )</p>
<p class="desc">Percentage of contributions covered by an appropriate IP log.</p>
<p class="desc">Eclipse foundation has a very strict <a href="https://www.eclipse.org/org/documents/Eclipse_IP_Policy.pdf">IP policy</a> and this measure should always be 100%.</p>
</li>
                      <li class="list-group-item"><p id="LIC_IDENT"><!-- span class="glyphicon glyphicon-record" / -->&nbsp;<strong>License identification</strong> ( LIC_IDENT )</p>
<p class="desc">Is there a list of the different licences used in the product?</p>
<p class="desc">This measure may use an external tool like Ninka (<a href="http://ninka.turingmachine.org/">ninka.turingmachine.org</a>) to identify the licence of components used in the project. Another way would be to identify a file named LICENCES in the root folder.</p>
</li>
                    </ul>
                  </div>  
              </div>
            </div>
          </div>
        </div>    </div>

    <!--[if lt IE 7]>
    <p class="browsehappy">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</p>
    <![endif]-->

    <!-- Google Analytics: change UA-XXXXX-X to be your site ID. -->
    <script>
      (function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=
      function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;
      e=o.createElement(i);r=o.getElementsByTagName(i)[0];
      e.src='//www.google-analytics.com/analytics.js';
      r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));
      ga('create','UA-XXXXX-X');ga('send','pageview');
    </script>

    <!-- jQuery -->
    <script src="/js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="/js/bootstrap.min.js"></script>

    <!-- Metis Menu Plugin JavaScript -->
    <script src="/js/plugins/metisMenu/metisMenu.min.js"></script>

    <!-- Custom Theme JavaScript -->
    <script src="/js/sb-admin-2.js"></script>
        
</body>
</html>
